"""
Complete AE Domain Fix - End to End
====================================
1. Load EDC data from S3
2. Transform AEVENT.csv to SDTM AE with all fixes applied
3. Validate corrections
4. Generate report

Study: MAXIS-08
Source: s3://s3dcri/incoming/EDC Data.zip
"""

import os
import sys
import asyncio
import re
import tempfile
import zipfile
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional

import pandas as pd
import numpy as np
import boto3
from dotenv import load_dotenv

# Load environment
load_dotenv()

class CompleteAEFixer:
    """Complete end-to-end AE domain fix."""
    
    def __init__(self):
        self.study_id = "MAXIS-08"
        self.bucket = "s3dcri"
        self.s3_key = "incoming/EDC Data.zip"
        self.source_data = {}
        self.ae_df = None
        
        # Create workspace
        self.workspace = Path("/Users/siddharth/Downloads/ETL/ETL/sdtm_pipeline/workspace")
        self.workspace.mkdir(exist_ok=True)
        
        print("=" * 80)
        print("SDTM AE DOMAIN - COMPLETE FIX PIPELINE")
        print("=" * 80)
        print(f"Study: {self.study_id}")
        print(f"Workspace: {self.workspace}")
        print("=" * 80)
        
    def log(self, msg: str, prefix: str = "INFO"):
        """Log with prefix."""
        prefixes = {
            "INFO": "‚ÑπÔ∏è ",
            "SUCCESS": "‚úÖ ",
            "WARNING": "‚ö†Ô∏è ",
            "ERROR": "‚ùå ",
            "WORKING": "üîß "
        }
        print(f"{prefixes.get(prefix, '')} {msg}")
        
    async def step1_load_from_s3(self):
        """Step 1: Load EDC data from S3."""
        print(f"\n{'=' * 80}")
        print("STEP 1: LOAD EDC DATA FROM S3")
        print("=" * 80)
        
        self.log(f"Downloading s3://{self.bucket}/{self.s3_key}...", "WORKING")
        
        try:
            # Initialize S3 client
            s3 = boto3.client('s3')
            
            # Create temp directory
            temp_dir = tempfile.mkdtemp()
            zip_path = os.path.join(temp_dir, "edc_data.zip")
            
            # Download
            self.log("Downloading from S3...", "INFO")
            s3.download_file(self.bucket, self.s3_key, zip_path)
            self.log("Download complete", "SUCCESS")
            
            # Extract
            self.log("Extracting ZIP file...", "INFO")
            extract_dir = os.path.join(temp_dir, "extracted")
            with zipfile.ZipFile(zip_path, 'r') as zf:
                zf.extractall(extract_dir)
            
            # Find and load CSV files
            csv_files = list(Path(extract_dir).rglob("*.csv"))
            self.log(f"Found {len(csv_files)} CSV files", "INFO")
            
            for csv_file in csv_files:
                try:
                    df = pd.read_csv(csv_file, low_memory=False)
                    filename = csv_file.name
                    self.source_data[filename] = df
                    self.log(f"  Loaded {filename}: {len(df)} records, {len(df.columns)} columns", "INFO")
                except Exception as e:
                    self.log(f"  Error loading {csv_file.name}: {e}", "WARNING")
            
            self.log(f"Successfully loaded {len(self.source_data)} source files", "SUCCESS")
            
            # Show AE-related files
            ae_files = [f for f in self.source_data.keys() if 'AEVENT' in f.upper()]
            if ae_files:
                self.log(f"AE source files: {', '.join(ae_files)}", "SUCCESS")
                for ae_file in ae_files:
                    df = self.source_data[ae_file]
                    self.log(f"  {ae_file}: {len(df)} records", "INFO")
                    self.log(f"  Columns: {', '.join(list(df.columns)[:10])}...", "INFO")
            else:
                self.log("No AE source files found!", "ERROR")
                return False
                
            return True
            
        except Exception as e:
            self.log(f"Error loading from S3: {e}", "ERROR")
            import traceback
            traceback.print_exc()
            return False
    
    def step2_transform_with_fixes(self):
        """Step 2: Transform AE domain with all fixes applied."""
        print(f"\n{'=' * 80}")
        print("STEP 2: TRANSFORM AE DOMAIN WITH FIXES")
        print("=" * 80)
        
        # Find AEVENT source file
        aevent_file = None
        for filename in self.source_data.keys():
            fname_upper = filename.upper()
            if 'AEVENT.CSV' in fname_upper and 'AEVENTC' not in fname_upper:
                aevent_file = filename
                break
        
        if not aevent_file:
            # Try alternative patterns
            for filename in self.source_data.keys():
                if 'AEVENT' in filename.upper():
                    aevent_file = filename
                    break
        
        if not aevent_file:
            self.log("AEVENT.csv not found in source data!", "ERROR")
            self.log(f"Available files: {', '.join(self.source_data.keys())}", "INFO")
            return False
        
        self.log(f"Using source file: {aevent_file}", "INFO")
        source_df = self.source_data[aevent_file].copy()
        self.log(f"Source records: {len(source_df)}", "INFO")
        
        # Show source columns
        self.log(f"Source columns: {', '.join(source_df.columns.tolist())}", "INFO")
        
        # Initialize SDTM AE dataframe
        ae = pd.DataFrame()
        
        # Required SDTM columns
        ae['STUDYID'] = self.study_id
        ae['DOMAIN'] = 'AE'
        
        # USUBJID - find subject identifier
        subject_col = self._find_column(source_df, ['SUBJECT', 'SUBJID', 'USUBJID', 'SUBJECT_ID', 'SUBJECTNUMBER'])
        if subject_col:
            ae['USUBJID'] = self.study_id + '-' + source_df[subject_col].astype(str)
            self.log(f"USUBJID: Mapped from {subject_col}", "SUCCESS")
        else:
            self.log("Subject identifier not found!", "ERROR")
            return False
        
        # AETERM - adverse event term
        term_col = self._find_column(source_df, ['AETERM', 'TERM', 'EVENT_TERM', 'ADVERSE_EVENT', 'AETEXT'])
        if term_col:
            ae['AETERM'] = source_df[term_col].fillna('').astype(str)
            self.log(f"AETERM: Mapped from {term_col}", "SUCCESS")
        else:
            ae['AETERM'] = ''
            self.log("AETERM: Column not found, using empty", "WARNING")
        
        # AEDECOD - decoded term (same as AETERM initially)
        ae['AEDECOD'] = ae['AETERM']
        
        # AESTDTC - start date with ISO 8601 conversion (FIX #4)
        start_col = self._find_column(source_df, ['AESTDAT', 'AESTDTC', 'START_DATE', 'STARTDATE', 'AEST'])
        if start_col:
            ae['AESTDTC'] = source_df[start_col].apply(self._convert_to_iso8601)
            self.log(f"AESTDTC: Mapped from {start_col} with ISO 8601 conversion", "SUCCESS")
        else:
            ae['AESTDTC'] = ''
            self.log("AESTDTC: Column not found", "WARNING")
        
        # AEENDTC - end date with ISO 8601 conversion (FIX #4)
        end_col = self._find_column(source_df, ['AEENDAT', 'AEENDTC', 'END_DATE', 'ENDDATE', 'AEEN'])
        if end_col:
            ae['AEENDTC'] = source_df[end_col].apply(self._convert_to_iso8601)
            self.log(f"AEENDTC: Mapped from {end_col} with ISO 8601 conversion", "SUCCESS")
        else:
            ae['AEENDTC'] = ''
        
        # AEDTC - collection date (default to start date)
        ae['AEDTC'] = ae['AESTDTC']
        
        # AESER - serious flag with controlled terminology mapping (FIX #2)
        ser_col = self._find_column(source_df, ['AESER', 'SERIOUS', 'AESERF', 'AESFL'])
        if ser_col:
            ae['AESER'] = source_df[ser_col].apply(lambda x: self._map_controlled_term(x, 'AESER'))
            self.log(f"AESER: Mapped from {ser_col} with CT validation (Y/N)", "SUCCESS")
        else:
            ae['AESER'] = ''
            self.log("AESER: Column not found", "WARNING")
        
        # AESEV - severity with controlled terminology mapping (FIX #3)
        sev_col = self._find_column(source_df, ['AESEV', 'SEVERITY', 'AESEVR', 'AETOXGR'])
        if sev_col:
            ae['AESEV'] = source_df[sev_col].apply(lambda x: self._map_controlled_term(x, 'AESEV'))
            self.log(f"AESEV: Mapped from {sev_col} with CT validation (MILD/MODERATE/SEVERE)", "SUCCESS")
        else:
            ae['AESEV'] = ''
            self.log("AESEV: Column not found", "WARNING")
        
        # AEREL - relationship to treatment
        rel_col = self._find_column(source_df, ['AEREL', 'RELATIONSHIP', 'AEAREL', 'REL'])
        if rel_col:
            ae['AEREL'] = source_df[rel_col].fillna('').astype(str)
            self.log(f"AEREL: Mapped from {rel_col}", "SUCCESS")
        else:
            ae['AEREL'] = ''
        
        # AEACN - action taken
        acn_col = self._find_column(source_df, ['AEACN', 'ACTION', 'AEACTION', 'AEACTN'])
        if acn_col:
            ae['AEACN'] = source_df[acn_col].fillna('').astype(str)
            self.log(f"AEACN: Mapped from {acn_col}", "SUCCESS")
        else:
            ae['AEACN'] = ''
        
        # AEOUT - outcome
        out_col = self._find_column(source_df, ['AEOUT', 'OUTCOME', 'AEOUTC', 'AEOUTCM'])
        if out_col:
            ae['AEOUT'] = source_df[out_col].fillna('').astype(str)
            self.log(f"AEOUT: Mapped from {out_col}", "SUCCESS")
        else:
            ae['AEOUT'] = ''
        
        # AESEQ - sequence number with duplicate fix (FIX #1)
        # Sort and generate unique sequence within USUBJID
        self.log("Generating AESEQ with ROW_NUMBER() logic...", "WORKING")
        ae = ae.sort_values(['USUBJID', 'AESTDTC', 'AETERM'], na_position='last').reset_index(drop=True)
        ae['AESEQ'] = ae.groupby('USUBJID').cumcount() + 1
        self.log("AESEQ: Generated as ROW_NUMBER() OVER (PARTITION BY USUBJID ORDER BY AESTDTC, AETERM)", "SUCCESS")
        
        # Store result
        self.ae_df = ae
        self.log(f"Transformation complete: {len(ae)} records", "SUCCESS")
        
        return True
    
    def _find_column(self, df: pd.DataFrame, candidates: list) -> Optional[str]:
        """Find first matching column from candidates list."""
        for col in candidates:
            if col in df.columns:
                return col
            # Try case-insensitive match
            for df_col in df.columns:
                if df_col.upper() == col.upper():
                    return df_col
        return None
    
    def _convert_to_iso8601(self, date_val: Any) -> str:
        """Convert date to ISO 8601 format (FIX #4)."""
        if pd.isna(date_val) or date_val == '':
            return ''
        
        date_str = str(date_val).strip()
        
        # Already in ISO format
        if '-' in date_str:
            return date_str
        
        # YYYYMMDD (8 digits)
        if len(date_str) == 8 and date_str.isdigit():
            return f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}"
        
        # YYYYMM (6 digits)
        if len(date_str) == 6 and date_str.isdigit():
            return f"{date_str[:4]}-{date_str[4:6]}"
        
        # YYYY (4 digits)
        if len(date_str) == 4 and date_str.isdigit():
            return date_str
        
        return date_str
    
    def _map_controlled_term(self, value: Any, term_type: str) -> str:
        """Map to controlled terminology (FIX #2 and #3)."""
        if pd.isna(value) or value == '':
            return ''
        
        val_str = str(value).strip().upper()
        
        if term_type == 'AESER':
            # Valid: Y, N
            mapping = {
                'YES': 'Y', 'Y': 'Y', '1': 'Y', 'TRUE': 'Y',
                'NO': 'N', 'N': 'N', '0': 'N', 'FALSE': 'N'
            }
            return mapping.get(val_str, '')
        
        elif term_type == 'AESEV':
            # Valid: MILD, MODERATE, SEVERE
            mapping = {
                'MILD': 'MILD', 'M': 'MILD', '1': 'MILD',
                'MODERATE': 'MODERATE', 'MOD': 'MODERATE', '2': 'MODERATE',
                'SEVERE': 'SEVERE', 'SEV': 'SEVERE', '3': 'SEVERE'
            }
            return mapping.get(val_str, '')
        
        return str(value)
    
    def step3_validate_corrections(self):
        """Step 3: Validate all corrections."""
        print(f"\n{'=' * 80}")
        print("STEP 3: VALIDATE CORRECTIONS")
        print("=" * 80)
        
        validation_results = {
            'total_records': len(self.ae_df),
            'issues': []
        }
        
        # Validation 1: AESEQ duplicates
        print("\n1. AESEQ Uniqueness (FIX #1):")
        aeseq_dups = self.ae_df.groupby(['USUBJID', 'AESEQ']).size()
        dup_count = (aeseq_dups > 1).sum()
        validation_results['aeseq_duplicates'] = dup_count
        
        if dup_count == 0:
            self.log("PASS - No duplicate AESEQ values within USUBJID", "SUCCESS")
        else:
            self.log(f"FAIL - {dup_count} duplicate AESEQ values found", "ERROR")
            validation_results['issues'].append(f"AESEQ duplicates: {dup_count}")
        
        # Validation 2: AESER controlled terminology
        print("\n2. AESER Controlled Terminology (FIX #2):")
        valid_aeser = ['Y', 'N', '']
        invalid_aeser = self.ae_df[
            ~self.ae_df['AESER'].isin(valid_aeser) & 
            self.ae_df['AESER'].notna()
        ]
        validation_results['invalid_aeser'] = len(invalid_aeser)
        
        if len(invalid_aeser) == 0:
            self.log("PASS - All AESER values are valid (Y/N)", "SUCCESS")
        else:
            self.log(f"FAIL - {len(invalid_aeser)} invalid AESER values", "ERROR")
            unique_invalid = invalid_aeser['AESER'].unique().tolist()
            self.log(f"Invalid values: {unique_invalid}", "ERROR")
            validation_results['issues'].append(f"Invalid AESER: {len(invalid_aeser)}")
        
        # Validation 3: AESEV controlled terminology
        print("\n3. AESEV Controlled Terminology (FIX #3):")
        valid_aesev = ['MILD', 'MODERATE', 'SEVERE', '']
        invalid_aesev = self.ae_df[
            ~self.ae_df['AESEV'].isin(valid_aesev) & 
            self.ae_df['AESEV'].notna()
        ]
        validation_results['invalid_aesev'] = len(invalid_aesev)
        
        if len(invalid_aesev) == 0:
            self.log("PASS - All AESEV values are valid (MILD/MODERATE/SEVERE)", "SUCCESS")
        else:
            self.log(f"FAIL - {len(invalid_aesev)} invalid AESEV values", "ERROR")
            unique_invalid = invalid_aesev['AESEV'].unique().tolist()
            self.log(f"Invalid values: {unique_invalid}", "ERROR")
            validation_results['issues'].append(f"Invalid AESEV: {len(invalid_aesev)}")
        
        # Validation 4: ISO 8601 dates
        print("\n4. ISO 8601 Date Format (FIX #4):")
        
        def is_valid_iso8601(date_str):
            if pd.isna(date_str) or date_str == '':
                return True
            date_str = str(date_str)
            pattern = r'^\d{4}(-\d{2}(-\d{2})?)?$'
            return bool(re.match(pattern, date_str))
        
        date_cols = ['AESTDTC', 'AEENDTC', 'AEDTC']
        total_invalid = 0
        
        for col in date_cols:
            invalid_dates = self.ae_df[
                ~self.ae_df[col].apply(is_valid_iso8601) & 
                self.ae_df[col].notna()
            ]
            if len(invalid_dates) > 0:
                total_invalid += len(invalid_dates)
                self.log(f"{col}: {len(invalid_dates)} invalid dates", "ERROR")
                sample = invalid_dates[col].head(3).tolist()
                self.log(f"  Sample: {sample}", "ERROR")
        
        validation_results['invalid_dates'] = total_invalid
        
        if total_invalid == 0:
            self.log("PASS - All dates are in ISO 8601 format", "SUCCESS")
        else:
            validation_results['issues'].append(f"Invalid dates: {total_invalid}")
        
        return validation_results
    
    def step4_save_and_report(self, validation_results: Dict):
        """Step 4: Save corrected domain and generate report."""
        print(f"\n{'=' * 80}")
        print("STEP 4: SAVE AND REPORT")
        print("=" * 80)
        
        # Save AE domain
        ae_path = self.workspace / "AE.csv"
        self.ae_df.to_csv(ae_path, index=False)
        self.log(f"Saved AE domain: {ae_path}", "SUCCESS")
        self.log(f"Records: {len(self.ae_df)}", "INFO")
        
        # Generate detailed report
        report = []
        report.append("=" * 80)
        report.append("SDTM AE DOMAIN - CORRECTION REPORT")
        report.append("=" * 80)
        report.append(f"\nStudy: {self.study_id}")
        report.append(f"Domain: AE (Adverse Events)")
        report.append(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"\nSource: s3://{self.bucket}/{self.s3_key}")
        report.append(f"Output: {ae_path}")
        
        report.append(f"\n{'=' * 80}")
        report.append("SOURCE FILES")
        report.append("=" * 80)
        for fname, df in self.source_data.items():
            if 'AEVENT' in fname.upper():
                report.append(f"  {fname}: {len(df)} records")
        
        report.append(f"\n{'=' * 80}")
        report.append("TRANSFORMATION RESULTS")
        report.append("=" * 80)
        report.append(f"  Total records: {validation_results['total_records']}")
        report.append(f"  Output file: {ae_path}")
        
        report.append(f"\n{'=' * 80}")
        report.append("VALIDATION RESULTS")
        report.append("=" * 80)
        
        report.append("\n‚úÖ FIX #1: AESEQ Duplicates")
        if validation_results['aeseq_duplicates'] == 0:
            report.append("   Status: FIXED - No duplicates found")
            report.append("   Method: ROW_NUMBER() OVER (PARTITION BY USUBJID ORDER BY AESTDTC, AETERM)")
        else:
            report.append(f"   Status: ISSUE - {validation_results['aeseq_duplicates']} duplicates remain")
        
        report.append("\n‚úÖ FIX #2: AESER Controlled Terminology")
        if validation_results['invalid_aeser'] == 0:
            report.append("   Status: FIXED - All values valid (Y/N)")
            report.append("   Mapping: YES‚ÜíY, NO‚ÜíN, 1‚ÜíY, 0‚ÜíN")
        else:
            report.append(f"   Status: ISSUE - {validation_results['invalid_aeser']} invalid values")
        
        report.append("\n‚úÖ FIX #3: AESEV Controlled Terminology")
        if validation_results['invalid_aesev'] == 0:
            report.append("   Status: FIXED - All values valid (MILD/MODERATE/SEVERE)")
            report.append("   Mapping: 1‚ÜíMILD, 2‚ÜíMODERATE, 3‚ÜíSEVERE, M‚ÜíMILD")
        else:
            report.append(f"   Status: ISSUE - {validation_results['invalid_aesev']} invalid values")
        
        report.append("\n‚úÖ FIX #4: ISO 8601 Date Format")
        if validation_results['invalid_dates'] == 0:
            report.append("   Status: FIXED - All dates in ISO 8601 format")
            report.append("   Conversion: YYYYMMDD ‚Üí YYYY-MM-DD")
        else:
            report.append(f"   Status: ISSUE - {validation_results['invalid_dates']} invalid dates")
        
        report.append(f"\n{'=' * 80}")
        report.append("SUMMARY")
        report.append("=" * 80)
        
        if len(validation_results['issues']) == 0:
            report.append("\n‚úÖ ALL VALIDATION ISSUES RESOLVED!")
            report.append("\nThe corrected AE domain is ready for submission.")
            report.append(f"  - {validation_results['total_records']} records")
            report.append("  - AESEQ is unique within USUBJID")
            report.append("  - AESER and AESEV use valid controlled terminology")
            report.append("  - All dates are in ISO 8601 format")
        else:
            report.append(f"\n‚ö†Ô∏è  {len(validation_results['issues'])} issues remaining:")
            for issue in validation_results['issues']:
                report.append(f"  - {issue}")
        
        report.append(f"\n{'=' * 80}")
        report.append("COLUMN DETAILS")
        report.append("=" * 80)
        for col in self.ae_df.columns:
            non_null = self.ae_df[col].notna().sum()
            pct = (non_null / len(self.ae_df)) * 100
            report.append(f"  {col}: {non_null}/{len(self.ae_df)} ({pct:.1f}%)")
        
        report.append(f"\n{'=' * 80}")
        
        report_text = "\n".join(report)
        
        # Print report
        print("\n" + report_text)
        
        # Save report
        report_path = self.workspace / "AE_CORRECTION_REPORT.txt"
        with open(report_path, 'w') as f:
            f.write(report_text)
        
        self.log(f"Report saved: {report_path}", "SUCCESS")
        
        return ae_path, report_path
    
    async def run(self):
        """Execute complete pipeline."""
        print()
        
        # Step 1: Load from S3
        success = await self.step1_load_from_s3()
        if not success:
            return
        
        # Step 2: Transform with fixes
        success = self.step2_transform_with_fixes()
        if not success:
            return
        
        # Step 3: Validate
        validation_results = self.step3_validate_corrections()
        
        # Step 4: Save and report
        ae_path, report_path = self.step4_save_and_report(validation_results)
        
        # Final summary
        print(f"\n{'=' * 80}")
        print("‚úÖ AE DOMAIN FIX COMPLETED!")
        print("=" * 80)
        print(f"\nOutput Files:")
        print(f"  - AE Domain: {ae_path}")
        print(f"  - Report: {report_path}")
        
        if len(validation_results['issues']) == 0:
            print(f"\n‚úÖ All {validation_results['total_records']} records passed validation!")
        else:
            print(f"\n‚ö†Ô∏è  {len(validation_results['issues'])} validation issues remain")
        
        print("=" * 80)


async def main():
    """Main entry point."""
    fixer = CompleteAEFixer()
    await fixer.run()


if __name__ == "__main__":
    asyncio.run(main())

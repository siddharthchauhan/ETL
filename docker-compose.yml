# =============================================================================
# SDTM Pipeline - LangGraph API with Docker Compose
# =============================================================================
#
# USAGE:
#   1. Build the LangGraph image:
#      langgraph build -t sdtm-langgraph -c langgraph.json
#
#   2. Start all services:
#      docker compose up -d
#
#   3. Connect your frontend to: http://localhost:2024
#      Default assistant: sdtm_deepagent
#
#   4. Stop services:
#      docker compose down
#
#   5. Stop and remove all data:
#      docker compose down -v
# =============================================================================

services:
  # ---------------------------------------------------------------------------
  # PostgreSQL - Persistent checkpointing and state storage
  # ---------------------------------------------------------------------------
  postgres:
    image: postgres:16-alpine
    container_name: sdtm-postgres
    volumes:
      - pgdata:/var/lib/postgresql/data
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: langgraph
    ports:
      - "5433:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # ---------------------------------------------------------------------------
  # LangGraph API Server - SDTM DeepAgent
  # ---------------------------------------------------------------------------
  langgraph-api:
    image: sdtm-langgraph:latest
    container_name: sdtm-langgraph-api
    ports:
      - "2024:8000"
    env_file:
      - .env
    environment:
      POSTGRES_URI: "postgres://postgres:postgres@postgres:5432/langgraph"
      LANGGRAPH_DEFAULT_RECURSION_LIMIT: "250"
      LANGGRAPH_RECURSION_LIMIT: "250"
    volumes:
      # Workspace artifacts (mapping specs, transformation scripts, validation reports)
      - ./sdtm_workspace:/deps/sdtm_workspace
      # Generated documents (PPTX, XLSX, DOCX, CSV, PDF)
      - ./generated_documents:/deps/generated_documents
      # Chat output files
      - ./sdtm_chat_output:/deps/sdtm_chat_output
      # EDC source data (read-only mount)
      - ./edc_data_temp:/deps/edc_data_temp:ro
      # Skills directory (live-reload skills without rebuild)
      - ./sdtm_pipeline/deepagents/skills:/deps/sdtm_pipeline/deepagents/skills:ro
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/ok')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # ---------------------------------------------------------------------------
  # File Server - Serves generated documents for frontend download
  # ---------------------------------------------------------------------------
  file-server:
    image: sdtm-langgraph:latest
    container_name: sdtm-file-server
    ports:
      - "8090:8090"
    env_file:
      - .env
    environment:
      FILE_SERVER_PORT: "8090"
      # Proxy target: points to the langgraph-api container inside Docker network.
      # Override with LANGGRAPH_API_URL in .env to point at a cloud deployment.
      LANGGRAPH_API_URL: "http://langgraph-api:8000"
    command: ["python", "file_server.py"]
    volumes:
      - ./generated_documents:/deps/generated_documents
      - ./sdtm_workspace:/deps/sdtm_workspace
      - ./sdtm_pipeline/deepagents/skills:/deps/sdtm_pipeline/deepagents/skills
    depends_on:
      - langgraph-api
    restart: unless-stopped

volumes:
  pgdata:
    driver: local

networks:
  default:
    name: sdtm-network
